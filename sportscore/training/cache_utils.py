"""
Cache Utilities

Functions for managing model configuration caches and training data files.
Sport-agnostic: callers provide paths and constants.
"""

import os
import glob
import json
import csv

import pandas as pd


def get_latest_training_csv(
    output_dir: str,
    prefix: str = 'classifier_training_',
    no_per: bool = False
) -> str:
    """
    Find the most recent training CSV file.

    Args:
        output_dir: Directory to search for CSV files
        prefix: Filename prefix to match (default: 'classifier_training_')
        no_per: If True, look for files with 'no_per' in the name

    Returns:
        Path to the most recent training CSV file, or None if not found
    """
    pattern = os.path.join(output_dir, f'{prefix}*.csv')
    csv_files = glob.glob(pattern)

    # Filter out standardized versions
    csv_files = [f for f in csv_files if '_standardized' not in f]

    # Filter based on no_per flag
    if no_per:
        csv_files = [f for f in csv_files if 'no_per' in f]
    else:
        csv_files = [f for f in csv_files if 'no_per' not in f]

    if not csv_files:
        return None

    csv_files.sort(key=os.path.getmtime, reverse=True)
    return csv_files[0]


def load_model_cache(cache_file: str) -> dict:
    """
    Load cached model configurations.

    Args:
        cache_file: Path to JSON cache file

    Returns:
        Dict with 'configs', 'best', 'timestamp' keys
    """
    if os.path.exists(cache_file):
        with open(cache_file, 'r') as f:
            return json.load(f)
    return {'configs': [], 'best': None, 'timestamp': None}


def save_model_cache(cache: dict, cache_file: str):
    """
    Save model configurations to cache.

    Args:
        cache: Dict with model configurations
        cache_file: Path to JSON cache file
    """
    os.makedirs(os.path.dirname(cache_file), exist_ok=True)
    with open(cache_file, 'w') as f:
        json.dump(cache, f, indent=2)


def get_best_config(cache: dict) -> dict:
    """
    Get the best model configuration from cache based on accuracy.

    Args:
        cache: Dict with 'configs' list

    Returns:
        Best config dict, or None if no configs
    """
    if not cache.get('configs'):
        return None

    sorted_configs = sorted(
        cache['configs'],
        key=lambda x: (-x['accuracy_mean'], x['log_loss_mean'])
    )
    return sorted_configs[0]


def read_csv_safe(csv_path: str, team_string_columns: list = None) -> pd.DataFrame:
    """
    Read CSV file with error handling for trailing empty columns.

    Args:
        csv_path: Path to CSV file
        team_string_columns: Column names to keep as strings (default: ['Home', 'Away'])

    Returns:
        DataFrame with trailing empty columns removed
    """
    if team_string_columns is None:
        team_string_columns = ['Home', 'Away']
    rows = []
    with open(csv_path, 'r', encoding='utf-8') as f:
        reader = csv.reader(f)
        header = next(reader)
        # Remove trailing empty columns from header
        while header and (not header[-1] or header[-1].strip() == ''):
            header.pop()
        expected_cols = len(header)

        for row_num, row in enumerate(reader, start=2):
            if len(row) > expected_cols:
                row = row[:expected_cols]
            elif len(row) < expected_cols:
                row.extend([''] * (expected_cols - len(row)))

            if len(row) == expected_cols:
                rows.append(row)
            else:
                print(f"Warning: Row {row_num} has {len(row)} columns, expected {expected_cols}. Skipping.")

    df = pd.DataFrame(rows, columns=header)

    for col in df.columns:
        if col not in team_string_columns:
            try:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            except:
                pass

    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
    df = df.dropna(axis=1, how='all')

    return df
